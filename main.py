import os
import time
import traceback
import mysql.connector
from fastapi import FastAPI
from pydantic import BaseModel
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.prompts import PromptTemplate
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_chroma import Chroma
from fastapi.middleware.cors import CORSMiddleware



load_dotenv()
app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], 
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

embeddings = GoogleGenerativeAIEmbeddings(
    model="text-embedding-004", 
    google_api_key=os.getenv("GOOGLE_API_KEY")
)

vector_db = Chroma(
    persist_directory="./db_knowledge",
    embedding_function=embeddings
)


llm = ChatGoogleGenerativeAI(
    model="gemini-flash-lite-latest", 
    temperature=0.3,
    max_retries=2, 
    google_api_key=os.getenv("GOOGLE_API_KEY")
)

def get_db_connection():
    return mysql.connector.connect(
        host="localhost",
        user="root",          
        password="vuthebach",  
        database="yt_learning_db"   
    )


template = """
Báº¡n lÃ  má»™t ChuyÃªn gia GiÃ¡o dá»¥c vÃ  NhÃ  khoa há»c dá»¯ liá»‡u. 
Nhiá»‡m vá»¥: PhÃ¢n tÃ­ch ná»™i dung video dá»±a trÃªn Transcript Ä‘Æ°á»£c cung cáº¥p nhÆ°ng KHÃ”NG Bá»Š Lá»† THUá»˜C hoÃ n toÃ n vÃ o nÃ³.

QUY TRÃŒNH Xá»¬ LÃ:
1. XÃ¡c Ä‘á»‹nh cÃ¡c Keyword (Tá»« khÃ³a) vÃ  Chá»§ Ä‘á» chÃ­nh mÃ  video "{title}" Ä‘ang Ä‘á» cáº­p.
2. Sá»­ dá»¥ng kiáº¿n thá»©c chuyÃªn sÃ¢u cá»§a báº¡n (World Knowledge) Ä‘á»ƒ giáº£i thÃ­ch chi tiáº¿t vÃ  Ä‘áº§y Ä‘á»§ nháº¥t vá» cÃ¡c khÃ¡i niá»‡m Ä‘Ã³. 
3. Náº¿u Transcript bá»‹ thiáº¿u há»¥t hoáº·c sai lá»—i chÃ­nh táº£, hÃ£y dá»±a vÃ o ngá»¯ cáº£nh vÃ  tiÃªu Ä‘á» Ä‘á»ƒ khÃ´i phá»¥c kiáº¿n thá»©c chuáº©n.
4. Äáº£m báº£o báº£n phÃ¢n tÃ­ch cÃ³ cáº¥u trÃºc sÆ° pháº¡m, dá»… hiá»ƒu vÃ  mang tÃ­nh chuyÃªn gia.

Cáº¤U TRÃšC Äáº¦U RA (Markdown):
# ğŸ¯ Báº¢N CHáº¤T KIáº¾N THá»¨C: {title}
> (Giáº£i thÃ­ch giÃ¡ trá»‹ thá»±c táº¿ cá»§a kiáº¿n thá»©c nÃ y)

## ğŸ§  PHÃ‚N TÃCH CHI TIáº¾T (Theo khung sÆ°á»n video)
### 1. [Chá»§ Ä‘á» 1]
- **Giáº£i mÃ£:** (Giáº£i thÃ­ch chi tiáº¿t khÃ¡i niá»‡m, cÃ´ng thá»©c, hoáº·c logic Ä‘áº±ng sau)
- **Kiáº¿n thá»©c má»Ÿ rá»™ng:** (Nhá»¯ng kiáº¿n thá»©c chuyÃªn sÃ¢u ngoÃ i transcript)
- **VÃ­ dá»¥ minh há»a:** (VÃ­ dá»¥ thá»±c táº¿)

## ğŸ’¡ Tá»”NG Káº¾T & Lá»œI KHUYÃŠN HÃ€NH Äá»˜NG
- (Quy trÃ¬nh Ã¡p dá»¥ng kiáº¿n thá»©c nÃ y vÃ o thá»±c táº¿)

Transcript tham kháº£o:
{transcript}
"""

class VideoData(BaseModel):
    videoId: str
    title: str
    transcript: str

@app.get("/")
async def root():
    return {"message": "Python AI Service is Running!"}

import time
from tenacity import retry, stop_after_attempt, wait_exponential


@app.post("/ai/process")
async def process_video(data: VideoData):
    print(f"\nğŸš€ [Báº®T Äáº¦U] --- PhÃ¢n tÃ­ch: {data.title} ---")
    try:
        print("ğŸ“ BÆ°á»›c 1: Äang bÄƒm transcript vÃ  náº¡p vÃ o ChromaDB...")
        try:
            text_splitter_db = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
            docs_db = text_splitter_db.create_documents(
                [data.transcript], 
                metadatas=[{"title": data.title, "videoId": data.videoId}] 
            )
            vector_db.add_documents(docs_db)
            print("âœ… BÆ°á»›c 1 thÃ nh cÃ´ng: ÄÃ£ lÆ°u kiáº¿n thá»©c vÃ o Vector DB.")
        except Exception as e_db:
            print(f"âŒ Lá»–I BÆ¯á»šC 1 (Vector DB): {str(e_db)}")
            return {"status": "error", "message": f"Lá»—i lÆ°u Database kiáº¿n thá»©c: {str(e_db)}"}

        print("ğŸ“ BÆ°á»›c 2: Äang Ä‘Ã³ng gÃ³i Prompt chuyÃªn gia...")
        full_context = data.transcript[:15000] 
        prompt_info = PromptTemplate(template=template, input_variables=["title", "transcript"])
        final_prompt = prompt_info.format(title=data.title, transcript=full_context)
        print("âœ… BÆ°á»›c 2 thÃ nh cÃ´ng: Prompt Ä‘Ã£ sáºµn sÃ ng.")

        print(f"ğŸ“ BÆ°á»›c 3: Äang gá»i Gemini ({llm.model}) - Vui lÃ²ng Ä‘á»£i...")
        try:
            start_time = time.time()
            response = llm.invoke(final_prompt)
            duration = time.time() - start_time
            
            if response and response.content:
                print(f"âœ… BÆ°á»›c 3 thÃ nh cÃ´ng: AI Ä‘Ã£ pháº£n há»“i sau {duration:.2f} giÃ¢y.")
                return {
                    "status": "success",
                    "ai_analysis": response.content 
                }
            else:
                print("âš ï¸ Cáº¢NH BÃO: AI káº¿t ná»‘i thÃ nh cÃ´ng nhÆ°ng tráº£ vá» ná»™i dung Rá»–NG.")
                return {"status": "error", "message": "AI pháº£n há»“i rá»—ng (Empty Content)."}
                
        except Exception as e_ai:
            print(f"âŒ Lá»–I BÆ¯á»šC 3 (Gemini API): {str(e_ai)}")
            if "429" in str(e_ai) or "RESOURCE_EXHAUSTED" in str(e_ai):
                return {"status": "error", "message": "Háº¿t Quota (429). Äá»£i 30s rá»“i báº¥m láº¡i bro nhÃ©!"}
            return {"status": "error", "message": f"Lá»—i tá»« Gemini: {str(e_ai)}"}

    except Exception as e_main:
        import traceback
        print(f"ğŸ”¥ Lá»–I Há»† THá»NG Tá»”NG THá»‚:\n{traceback.format_exc()}")
        return {"status": "error", "message": f"Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: {str(e_main)}"}

class QuestionRequest(BaseModel):
    question: str

@app.post("/ai/ask-anything")
async def ask_anything(data: QuestionRequest):
    print(f"\nğŸ” [RAG] --- Nháº­n cÃ¢u há»i: {data.question} ---")
    try:
        related_docs = vector_db.similarity_search(data.question, k=3)
        
        if related_docs:
            context = "\n---\n".join([d.page_content for d in related_docs])
            print(f"âœ… TÃ¬m tháº¥y {len(related_docs)} Ä‘oáº¡n liÃªn quan.")
        else:
            context = "KhÃ´ng cÃ³ thÃ´ng tin cá»¥ thá»ƒ trong database."
            print("âš ï¸ Database khÃ´ng cÃ³ gÃ¬ liÃªn quan.")

        rag_prompt = f"""
        Báº¡n lÃ  trá»£ lÃ½ há»c táº­p. Dá»±a vÃ o kiáº¿n thá»©c sau: {context}
        ---
        CÃ¢u há»i: {data.question}
        YÃªu cáº§u: Tráº£ lá»i ngáº¯n gá»n báº±ng Markdown. Náº¿u khÃ´ng cÃ³ thÃ´ng tin, hÃ£y dÃ¹ng kiáº¿n thá»©c chuyÃªn gia cá»§a báº¡n.
        """

        print("ğŸ¤– Äang Ä‘á»£i Gemini 2.0 pháº£n há»“i...")
        response = llm.invoke(rag_prompt)
        
        ai_text = ""
        if response and response.content:
            if isinstance(response.content, list):
                ai_text = " ".join([block['text'] for block in response.content if 'text' in block])
            else:
                ai_text = str(response.content)
            
            print(f"âœ… AI tráº£ lá»i thÃ nh cÃ´ng ({len(ai_text)} kÃ½ tá»±).")
            return {"answer": ai_text}
        
        print("âš ï¸ AI tráº£ vá» rá»—ng.")
        return {"answer": "AI khÃ´ng tráº£ vá» ná»™i dung."}

    except Exception as e:
        error_msg = str(e)
        print(f"âŒ Lá»–I RAG: {error_msg}")
        
        if "429" in error_msg or "RESOURCE_EXHAUSTED" in error_msg:
            return {"answer": "QUOTA_EXCEEDED"} 
            
        return {"answer": f"Lá»—i há»‡ thá»‘ng: {error_msg}"}
    
@app.get("/api/video/history")
async def get_video_history():
    print("[DEBUG] ğŸ“‚ Äang lÃ´i lá»‹ch sá»­ video tá»« MySQL...")
    try:
        conn = get_db_connection()
        cursor = conn.cursor(dictionary=True)
        
        query = "SELECT videoId, title, summary, createdAt FROM videos ORDER BY createdAt DESC"
        cursor.execute(query)
        
        data = cursor.fetchall()
        
        cursor.close()
        conn.close()
        
        print(f"âœ… ÄÃ£ tÃ¬m tháº¥y {len(data)} video trong lá»‹ch sá»­.")
        return data  

    except Exception as e:
        print(f"âŒ Lá»—i truy váº¥n MySQL: {str(e)}")
        return [] 
